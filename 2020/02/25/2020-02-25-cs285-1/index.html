<!DOCTYPE html>





<html class="theme-next muse use-motion" lang="ko">
<head>
  <meta charset="UTF-8">
<meta name="generator" content="Hexo 3.9.0">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.3.0">
  <link rel="mask-icon" href="/images/logo.svg?v=7.3.0" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.3.0">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '7.3.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":true},
    back2top: {"enable":true,"sidebar":true,"scrollpercent":false},
    save_scroll: true,
    copycode: {"enable":false,"show_result":false,"style":null},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '복사',
      copy_success: 'Copied',
      copy_failure: 'Copy failed'
    }
  };
</script>

  <meta name="description" content="CS 285 at UC Berkeley을 보고 정리한 글입니다. Terminology &amp;amp; notation image classification에서는 input으로 image로 받고 output으로 class이지만  순차적 의사결정 문제(sequential decision making problem)에서는 아래첨자에 time step $t$가 추가 되">
<meta name="keywords" content="Deep Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="CS285 Fa19 Deep Reinforcement Learning, Decision Making, and Control">
<meta property="og:url" content="https://juhwakkim.github.io/2020/02/25/2020-02-25-cs285-1/index.html">
<meta property="og:site_name" content="AI&amp;Robotics">
<meta property="og:description" content="CS 285 at UC Berkeley을 보고 정리한 글입니다. Terminology &amp;amp; notation image classification에서는 input으로 image로 받고 output으로 class이지만  순차적 의사결정 문제(sequential decision making problem)에서는 아래첨자에 time step $t$가 추가 되">
<meta property="og:locale" content="ko">
<meta property="og:image" content="https://juhwakkim.github.io/images/Deep-learning/cs285/cs285-1.jpg">
<meta property="og:image" content="https://juhwakkim.github.io/images/Deep-learning/cs285/cs285-1(2).jpg">
<meta property="og:image" content="https://juhwakkim.github.io/images/Deep-learning/cs285/cs285-1_.jpg">
<meta property="og:image" content="https://juhwakkim.github.io/images/Deep-learning/cs285/cs285-1(3).jpg">
<meta property="og:image" content="https://juhwakkim.github.io/images/Deep-learning/cs285/cs285-1(4).jpg">
<meta property="og:image" content="https://juhwakkim.github.io/images/Deep-learning/cs285/cs285-1(6).jpg">
<meta property="og:image" content="https://juhwakkim.github.io/images/Deep-learning/cs285/cs285-1(7).jpg">
<meta property="og:image" content="https://juhwakkim.github.io/images/Deep-learning/cs285/cs285-1(8).jpg">
<meta property="og:image" content="https://juhwakkim.github.io/images/Deep-learning/cs285/cs285-1(9).jpg">
<meta property="og:image" content="https://juhwakkim.github.io/images/Deep-learning/cs285/cs285-1(11).jpg">
<meta property="og:image" content="https://juhwakkim.github.io/images/Deep-learning/cs285/cs285-1(12).jpg">
<meta property="og:image" content="https://juhwakkim.github.io/images/Deep-learning/cs285/cs285-1(14).jpg">
<meta property="og:image" content="https://juhwakkim.github.io/images/Deep-learning/cs285/cs285-1(16).jpg">
<meta property="og:image" content="https://juhwakkim.github.io/images/Deep-learning/cs285/cs285-1(17).jpg">
<meta property="og:image" content="https://juhwakkim.github.io/images/Deep-learning/cs285/cs285-1(18).jpg">
<meta property="og:image" content="https://juhwakkim.github.io/images/Deep-learning/cs285/cs285-1(19).jpg">
<meta property="og:image" content="https://juhwakkim.github.io/images/Deep-learning/cs285/cs285-1(20).jpg">
<meta property="og:image" content="https://juhwakkim.github.io/images/Deep-learning/cs285/cs285-1(21).jpg">
<meta property="og:image" content="https://juhwakkim.github.io/images/Deep-learning/cs285/cs285-1(22).jpg">
<meta property="og:image" content="https://juhwakkim.github.io/images/Deep-learning/cs285/cs285-1(23).jpg">
<meta property="og:image" content="https://juhwakkim.github.io/images/Deep-learning/cs285/cs285-1(24).jpg">
<meta property="og:image" content="https://juhwakkim.github.io/images/Deep-learning/cs285/cs285-1(25).jpg">
<meta property="og:image" content="https://juhwakkim.github.io/images/Deep-learning/cs285/cs285-1(26).jpg">
<meta property="og:image" content="https://juhwakkim.github.io/images/Deep-learning/cs285/cs285-1(27).jpg">
<meta property="og:image" content="https://juhwakkim.github.io/images/Deep-learning/cs285/cs285-1(28).jpg">
<meta property="og:updated_time" content="2020-02-24T15:00:00.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="CS285 Fa19 Deep Reinforcement Learning, Decision Making, and Control">
<meta name="twitter:description" content="CS 285 at UC Berkeley을 보고 정리한 글입니다. Terminology &amp;amp; notation image classification에서는 input으로 image로 받고 output으로 class이지만  순차적 의사결정 문제(sequential decision making problem)에서는 아래첨자에 time step $t$가 추가 되">
<meta name="twitter:image" content="https://juhwakkim.github.io/images/Deep-learning/cs285/cs285-1.jpg">
  <link rel="canonical" href="https://juhwakkim.github.io/2020/02/25/2020-02-25-cs285-1/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>CS285 Fa19 Deep Reinforcement Learning, Decision Making, and Control | AI&Robotics</title>
  








  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="ko">

  <div class="container sidebar-position-left">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">AI&Robotics</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>홈</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-tags">
      
    
      
    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>태그<span class="badge">7</span></a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-categories">
      
    
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>카테고리<span class="badge">9</span></a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>아카이브<span class="badge">29</span></a>

  </li>
      <li class="menu-item menu-item-search">
        <a href="javascript:;" class="popup-trigger">
        
          <i class="menu-item-icon fa fa-search fa-fw"></i> <br>검색</a>
      </li>
    
  </ul>

    

    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>


    </div>
</nav>
</div>
    </header>

    

  <a href="https://github.com/juhwakKim" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content page-post-detail">
            

  <div id="posts" class="posts-expand">
    

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://juhwakkim.github.io/2020/02/25/2020-02-25-cs285-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Juhwak Kim">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AI&Robotics">
    </span>
      <header class="post-header">

        
          <h1 class="post-title" itemprop="name headline">CS285 Fa19 Deep Reinforcement Learning, Decision Making, and Control

            
          </h1>
        

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">작성일</span>

              
                
              

              <time title="Post created: 2020-02-25 00:00:00" itemprop="dateCreated datePublished" datetime="2020-02-25T00:00:00+09:00">2020-02-25</time>
            </span>
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/lecture/" itemprop="url" rel="index"><span itemprop="name">lecture</span></a></span>

                
                
              
            </span>
          

          
            
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="fa fa-comment-o"></i>
    </span>
    <span class="post-meta-item-text">댓글: </span>
  
    <a href="/2020/02/25/2020-02-25-cs285-1/#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2020/02/25/2020-02-25-cs285-1/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p><a href="http://rail.eecs.berkeley.edu/deeprlcourse/" target="_blank" rel="noopener">CS 285 at UC Berkeley</a>을 보고 정리한 글입니다.</p>
<h2 id="Terminology-amp-notation"><a href="#Terminology-amp-notation" class="headerlink" title="Terminology &amp; notation"></a>Terminology &amp; notation</h2><p><img src="/images/Deep-learning/cs285/cs285-1.jpg" alt="cs285" title="cs285 paper"></p>
<p>image classification에서는 input으로 image로 받고 output으로 class이지만 </p>
<p><strong>순차적 의사결정 문제(sequential decision making problem)</strong>에서는 아래첨자에 time step $t$가 추가 되고 output이 <strong>$\bf a_t$(action)</strong>이 된다. 그리고 순차적 의사결정 문제는 action이 <strong>observation($\bf o_t$)</strong>에 영향을 끼친다. </p>
<p><strong>$\pi_{\theta} \bf (a_t|o_t)$(policy)</strong>은 $o_t$가 주어졌을 때 $a_t$의 확률분포이다.</p>
<h4 id="observation-과-state의-차이"><a href="#observation-과-state의-차이" class="headerlink" title="observation 과 state의 차이"></a>observation 과 state의 차이</h4><p>observation($o_t$)는 input 이미지로 볼 수 있고 <strong>state($\bf s_t$)</strong>는 치타의 상태와 가젤의 상태(environment의 모든 정보)라 할 수 있다. 그래서 위 그림같이 이미지에서 자동차가 치타를 가리면 observation에서는 치타의 정보를 알 수 없지만 state는 알 수 있다.($\pi_{\theta} \bf (a_t|o_t)$는 partially observed라고 하고 $\pi_{\theta} \bf (a_t|s_t)$ fully observed라 한다.)</p>
<p><img src="/images/Deep-learning/cs285/cs285-1(2).jpg" alt="cs285" title="cs285 paper"></p>
<blockquote>
<p>$\bf p(s_{t+1}|s_t,a_t)$: state $\bf s_t$에서 action $\bf a_t$를 취했을때 $\bf s_{t+1}$로 갈 확률</p>
</blockquote>
<p>이러한 성질은 <strong>markov chain</strong>에서 보면 위 그림과 같다. 여기서 $\bf s_t$에서 $\bf s_{t+1}$로 갈때 $\bf s_{t-1}$은 이와 독립적이다.(future은 past에 독립) 이를 <strong>Markov property</strong>라고 한다.</p>
<p>위와 같은 그래프가 형성되기 위해서는 state가 필요한데 그 이유는 observation은 markov property를 만족하지 않기 때문이다. </p>
<p>ex) 위 치타와 차 예시를 보면 $\bf o_{t-1}$를 차가 치타를 가리기 전 $\bf o_t$를 차가 치타를 가린 경우 $\bf o_{t+1}$를 차가 지나간 후라면 $\bf o_{t+1}$는 $o_{t-1}$의 정보를 알지 못하면 알 수 없기에 markov property를 따르지 않는다.  </p>
<p><img src="/images/Deep-learning/cs285/cs285-1_.jpg" alt="cs285" title="cs285 paper"></p>
<p>가끔 state를 $\scr{x_t}$로 action을 $\bf u_t$로 나타내기도 한다.</p>
<h2 id="Imitation-Learning"><a href="#Imitation-Learning" class="headerlink" title="Imitation Learning"></a>Imitation Learning</h2><p><img src="/images/Deep-learning/cs285/cs285-1(3).jpg" alt="cs285" title="cs285 paper"></p>
<p>사람(전문가)으로부터 observation $\bf o_t$와 action $\bf a_t$를 모아서 $\pi_\theta \bf (a_{t}|o_{t})$를 supervised learning 하는 것을  <strong>behavior cloning</strong>이라 한다.</p>
<p><img src="/images/Deep-learning/cs285/cs285-1(4).jpg" alt="cs285" title="cs285 paper"></p>
<blockquote>
<p>검은선: training data의 trajectory 빨간선: 학습시킨 $\pi_{\theta}$의 trajectory </p>
</blockquote>
<p>일반적으로 이러한 방법은 잘 안되는데 그 이유는 supervised learning이 정확하게 training data와 100% 똑같지 않기때문에 초반에 mistake가 일어나고 그 결과 모르는 trajectory로 가게 되고 계속해서 mistake가 커지기 때문이다.</p>
<h4 id="문제-개선"><a href="#문제-개선" class="headerlink" title="문제 개선"></a>문제 개선</h4><p><img src="/images/Deep-learning/cs285/cs285-1(6).jpg" alt="cs285" title="cs285 paper"></p>
<p><a href="https://arxiv.org/abs/1604.07316" target="_blank" rel="noopener">End to End Learning for Self-Driving Cars</a> 에서 위에서 나온 문제를 해결하기 위해 차에 3개의 카메라를 달아서 해결하였다. 왼쪽 카메라는 오른쪽 핸들로 bias를 오른쪽 카메라는 왼쪽 핸들로 bias를 주어 상호보완이 가능하게 하여 학습이 더 잘되게 하였다. 하지만 이 방법은 자율주행에서만 가능하다.</p>
<p><img src="/images/Deep-learning/cs285/cs285-1(7).jpg" alt="cs285" title="cs285 paper"></p>
<blockquote>
<p>trajectory의 distribution 안정적이게 되었다.</p>
</blockquote>
<p><img src="/images/Deep-learning/cs285/cs285-1(8).jpg" alt="cs285" title="cs285 paper"></p>
<blockquote>
<p>$\bf p_{\text {data}}(o_t)$: training data(observation)의 distribution<br>$\bf p_{\pi_\theta}(o_t)$: $\pi_\theta$를 따랐을때 나온 observation 의 distribution</p>
</blockquote>
<p>실제 training data는 $\bf p_{\text {data}}(o_t)$에서 sampling된 것으로 볼 수 있다.<br>여기서 $o_t$는 서로 독립적이지 않지만, supervised learning을 이용하기에 independent가 된다.</p>
<p>여기서 문제는 $\bf p_{\text {data}}(o_t)$와 $\bf p_{\pi_\theta}(o_t)$가 달라서 mistake가 생기게 된다는 것이다. 그렇다면 $\bf p_{\text {data}}(o_t) = p_{\pi_\theta}(o_t)$로 강제로 만들어 주면 어떻게 될까?</p>
<h3 id="DAgger"><a href="#DAgger" class="headerlink" title="DAgger"></a>DAgger</h3><p><img src="/images/Deep-learning/cs285/cs285-1(9).jpg" alt="cs285" title="cs285 paper"></p>
<p>여기서 우리는 policy를 data만큼 바꾸지 않을 것이다. DAgger의 idea는 training datg를 $\bf p_{\text {data}}(o_t)$가 아닌 $\bf p_{\pi_\theta}(o_t)$에서 모으는 것이다.</p>
<ol>
<li>human data로 $\bf \pi_\theta (a_t|o_t)$를 학습 시킨다.</li>
<li>$\bf \pi_\theta (a_t|o_t)$로 새로운 데이터($o_t$)를 얻는다.</li>
<li>사람이 새로운 데이터에 라벨($\bf a_t$)을 달아준다. </li>
<li>새로 얻은 데이터를 training data에 합친다.</li>
<li>1-4를 계속 반복한다.</li>
</ol>
<p>하지만 사람이 label을 정의 해주기 힘들고 너무나 많은 노동력이 든다는 문제점이 생긴다.</p>
<p><img src="/images/Deep-learning/cs285/cs285-1(11).jpg" alt="cs285" title="cs285 paper"></p>
<p>만약 모델이 drift가 생기지 않을 정도로 학습이 잘되고 overfit 되지 않는다면 성능이 올라갈 것이다. 하지만 그렇게는 잘되지 않는다.</p>
<h3 id="실패-원인"><a href="#실패-원인" class="headerlink" title="실패 원인"></a>실패 원인</h3><h4 id="Non-Markovian-behavior"><a href="#Non-Markovian-behavior" class="headerlink" title="Non-Markovian behavior"></a>Non-Markovian behavior</h4><p><img src="/images/Deep-learning/cs285/cs285-1(12).jpg" alt="cs285" title="cs285 paper"></p>
<p>$\bf \pi_\theta (a_t|o_t)$는 현재 observation에만 의존하여 행동하지만, 실제 사람은 과거의 observation도 고려하기에 문제가 발생하였다.</p>
<p><img src="/images/Deep-learning/cs285/cs285-1(14).jpg" alt="cs285" title="cs285 paper"></p>
<blockquote>
<p>위 문제의 해결방안중 하나는 RNN이다.</p>
</blockquote>
<h4 id="Multimodal-behavior"><a href="#Multimodal-behavior" class="headerlink" title="Multimodal behavior"></a>Multimodal behavior</h4><p><img src="/images/Deep-learning/cs285/cs285-1(16).jpg" alt="cs285" title="cs285 paper"></p>
<blockquote>
<p>파란색 바그래프는 discrete case를 나타낸 것이고 밑에는 continuous 정규분포(Maximum Likelihood)로 나타낸 것이고 이는 적용되지않는다.</p>
</blockquote>
<p>위 나무 그림처럼 같은 상황에서도 다양한 행동(왼쪽, 오른쪽)이 가능하다. 이러한 문제는 Output Mixture of Gaussians, Latent variable model, Autoregressive discretization으로 해결할 수 있다.</p>
<h4 id="Output-mixture-of-Gaussians"><a href="#Output-mixture-of-Gaussians" class="headerlink" title="Output mixture of Gaussians"></a>Output mixture of Gaussians</h4><p><img src="/images/Deep-learning/cs285/cs285-1(17).jpg" alt="cs285" title="cs285 paper"></p>
<p>action을 선택할 때 한 개의 Gaussian에서 뽑는 것이 아닌 여려 개의 Gaussian을 이용하는 방법이다.<br>하지만 이 방법은 n개의 action만 사용 가능 하므로 action이 많을수록 사용하기 힘들다는 단점이 있다. </p>
<h4 id="latent-variable-models"><a href="#latent-variable-models" class="headerlink" title="latent variable models"></a>latent variable models</h4><p><img src="/images/Deep-learning/cs285/cs285-1(18).jpg" alt="cs285" title="cs285 paper"></p>
<p>이 방법은 input에 노이즈를 추가해서 딥러닝 모델에 학습시킨다. 원하는 대로 표현이 가능하지만, 훈련이 어렵다는 단점이 있다.</p>
<h4 id="autoregressive-discretization"><a href="#autoregressive-discretization" class="headerlink" title="autoregressive discretization"></a>autoregressive discretization</h4><p><img src="/images/Deep-learning/cs285/cs285-1(19).jpg" alt="cs285" title="cs285 paper"></p>
<p>softmax를 통해 discrete한 확률분포를 뽑아내고 분포에서 sampling하여 또 다른 네트워크에 입력으로 넣어주고 다시 확률분포를 뽑아준다. 이 과정을 n번 반복하여 n개의 dimension을 출력으로 뽑아내게 된다.<br>이 방법은 만약 작은 차원의 action space를 가지고 있고 action space가 continuous이라도 discrete하게 바꿀 수 있다. 하지만 high dimential에서는 practical 하지 않다.</p>
<h3 id="Imitation-learning-recap"><a href="#Imitation-learning-recap" class="headerlink" title="Imitation learning: recap"></a>Imitation learning: recap</h3><p><img src="/images/Deep-learning/cs285/cs285-1(20).jpg" alt="cs285" title="cs285 paper"></p>
<p>Behavior cloning은 종종 이 방법만으로 불충분하다. 왜냐하면, distribution mismatch problem이 발생하기 때문이다.</p>
<p>하지만 다음과 같은 방법을 쓰면 잘 작동한다.</p>
<ol>
<li>Hacks (e.g 자율주행에서 카메라 3개를 쓴 방법)</li>
<li>안정적인 trajectory distribution으로부터 sampling</li>
<li>on-policy data를 추가한다. (e.g Dagger 사용)</li>
<li>더 정확하게 모델링 한다.</li>
</ol>
<h4 id="Imitation-learning의-한계"><a href="#Imitation-learning의-한계" class="headerlink" title="Imitation learning의 한계"></a>Imitation learning의 한계</h4><p><img src="/images/Deep-learning/cs285/cs285-1(21).jpg" alt="cs285" title="cs285 paper"></p>
<ul>
<li>사람이 data를 제공해야 한다.<ul>
<li>딥러닝은 data가 많을 때 잘된다.</li>
</ul>
</li>
<li>사람이 특정 action을 정해주기 힘든 경우도 있다.</li>
<li>사람은 자동으로 배우는데 기계는 그렇지 못한다.<ul>
<li>스스로 경험으로부터 무제한 데이터가 필요</li>
<li>연속적으로 스스로 improvement 해야 한다.</li>
</ul>
</li>
</ul>
<h4 id="learning-without-imitation"><a href="#learning-without-imitation" class="headerlink" title="learning without imitation"></a>learning without imitation</h4><p><img src="/images/Deep-learning/cs285/cs285-1(22).jpg" alt="cs285" title="cs285 paper"></p>
<blockquote>
<p>$\delta$: 사자한테 먹히면 1 아니면 0</p>
</blockquote>
<p>사자예시로 다시 돌아가보면 우리는 사자에게 먹히지 않는 것이 목표이다.(위 식의 기댓값을 minimize)</p>
<p><img src="/images/Deep-learning/cs285/cs285-1(23).jpg" alt="cs285" title="cs285 paper"></p>
<p>우리는 오늘도 내일도 모레도 먹히는 것을 원하지 않기에 위와 같이 state와 action의 sequence로 식을 바꿀 수 있다. 이 식은 강화학습 문제와 비슷하게 된다.</p>
<p><img src="/images/Deep-learning/cs285/cs285-1(24).jpg" alt="cs285" title="cs285 paper"></p>
<ul>
<li>cost function: 얼마나 나쁜 결과를 했는지를 나타낸다.(minimize)</li>
<li>reward function: 얼마나 잘했는지를 나타낸다(maximize)</li>
</ul>
<p><img src="/images/Deep-learning/cs285/cs285-1(25).jpg" alt="cs285" title="cs285 paper"></p>
<h4 id="cost-function-for-imitation-learning"><a href="#cost-function-for-imitation-learning" class="headerlink" title="cost function for imitation learning"></a>cost function for imitation learning</h4><p><img src="/images/Deep-learning/cs285/cs285-1(26).jpg" alt="cs285" title="cs285 paper"></p>
<p>imitation learning에서 reward function은 $\bf r(s,a) = \log p(\bf a = \pi ^\star (s)|s)$($\bf p(\bf a = \pi ^\star (s)|s)$은 action과 optimal policy가 같을 확률)으로 나타내고 cost function은 위 식과 같이 $\bf c(s,a)$로 나타내고 이는 틀린 횟수로 볼 수 있다.</p>
<h4 id="Distribution-mismatch-analysis"><a href="#Distribution-mismatch-analysis" class="headerlink" title="Distribution mismatch analysis"></a>Distribution mismatch analysis</h4><p><img src="/images/Deep-learning/cs285/cs285-1(27).jpg" alt="cs285" title="cs285 paper"></p>
<p>distribution mismatch 문제에서 time 축을 time step $\bf T$로 정의하고, cost function을 $\bf r(s,a) = \log  p(a=\pi^\star (s) | s)$로 log likelyhood loss를 사용해도 되지만 간단하게 분석하기 위해서 zero-one loss를 사용한다.</p>
<p>$$\bf c(s,a) = \begin{cases}<br>0 &amp; \ \ \text{ if } \ a = \pi ^\star (s) \ \cr<br>1 &amp; \ \ \  \text{otherwise.}<br>\end{cases} - (8) $$</p>
<p>tightrope로 예시를 들면, 위 grid 그림처럼 나타낼 수 있다.(빨간색이 낭떠러지) </p>
<p>학습이 어느정도 되서 모든$\bf s \in \mathit{D_{train}}$에 대해 $\pi_{\theta}(a \ne \pi^\star (s) | s) \leq \epsilon$이라 가정하자. 학습데이터의 모든 state에서 사람과 다른 행동(줄에서 떨어짐)을 할 확률이 $\epsilon$ 보다 작다는 것을 말한다($\epsilon$을 mistake할 확률으로 볼 수 있고 worst case이다.). $\epsilon$은 training method에 따라 값이 달라지고 method가 좋을수록 값이 작아진다.</p>
<p>이때 total cost 기댓값의 upper bound는 다음과 같다.</p>
<p>$$\bf \mathbb{E} \left[\  \mathsf{\underset{t}{\sum}}\  c(s_{t},a_{t})\right] \leq \epsilon T + (1-\epsilon)(\epsilon(T-1) + (1-\epsilon)(…))$$</p>
<p>첫번째 step에서 mistake했을때 cost의 기댓값은 $\bf \epsilon \bf T$(mistake를 하면 그 이후 step에서는 계속 mistake하므로)이고 첫번째는 잘하고 두번째 step에서 mistake했을때 cost의 기댓값은 $\bf (1-\epsilon)\epsilon(T-1)$이고 $\bf T$ step만큼의 항이 나온다. 그리고 각가의 항이 $\bf O(\epsilon T)$(Order of T)이기 때문에 $\bf \mathbb{E} [\  \mathsf{\underset{t}{\Sigma}}\  c(s_{t},a_{t})]$의 bound는 $O(\epsilon T^2)$가 된다.</p>
<p>하지만 $O(\epsilon T^2)$는 좋지 않다. 왜냐하면 $\epsilon$이 아무리 작아도 $T$가 길어질수록 cost가 커지기 때문이다. </p>
<p><img src="/images/Deep-learning/cs285/cs285-1(28).jpg" alt="cs285" title="cs285 paper"></p>
<p>위에서 했던 가정 “모든 $\bf s \in \mathit{D_{train}}$”은 trained state만 고려하기에 적절한 가정은아니다(image classification에서 train과 test를 똑같은 사진을 쓰는 것과 같음, generalization 문제). 그래서 가정을 $\bf s \sim p_{train}(s)$으로 바꾸자. </p>
<p>먼저 DAgger를 적용했을 때 $p_{train}(s) \rightarrow p_\theta(s)$($p_{train}(s) = p_\theta(s)$)이 된다. 이때 total cost 기댓값의 upper bound는</p>
<p>$$\bf \mathbb{E} \left[\  \mathsf{\underset{t}{\sum}}\  c(s_{t},a_{t})\right] \leq \epsilon T$$<br>이된다.(매 step마다 mistake할 확률이 $\epsilon$으로 동일하기 때문)</p>
<p>이제 DAgger를 쓰지않고 $\bf p_{train}(s) \ne p_{\theta}(s)$(train data의 상태분포와 trained된 상태분포가 다름)라 가정하자.</p>
<p>$$ \bf p_{\theta}(s_{t}) = (1-\epsilon)^t p_{train}(s_{t}) + (1-(1-\epsilon)^t)p_{mistake}(s_t)$$</p>
<p>여기서 $(1-\epsilon)^t$는 mistake를 하지 않을 확률이고 $\bf p_{mistake}(s_{t})$는 mistake했을때 확률분포이다.</p>
<p>$$ \bf | p_{\theta}(s_{t}) - p_{train}(s_{t})|  = \underset{s_{t}}{\sum} | p_{\theta}(s_{t}) -p_{train}(s_{t}) $$</p>
<blockquote>
<p>total variation divergence between $p_\theta(s_t)$ and $p_{train}(s_t)$</p>
</blockquote>
<p>$$\bf p_{\theta}(s_{t}) = (1-\epsilon)^t p_{train}(s_{t}) + (1-(1-\epsilon)^t)p_{mistake}(s_t)$$ </p>
<p>$$\bf p_{train}(s_t) = (1-\epsilon)^t p_{train} + (1-(1-\epsilon)^t)p_{train}$$</p>
<p>이므로 </p>
<p>$\bf \left| p_{\theta}(s_{t}) - p_{train}(s_{t}) \right| = (1-(1-\epsilon)^t) \left| p_{mistake}(s_{t})-p_{train}(s_{t}) \right|$이된다.</p>
<p>$$\bf \left| p_{\theta}(s_{t}) - p_{train}(s_{t}) \right| = (1-(1-\epsilon)^t) \left| p_{mistake}(s_{t})-p_{train}(s_{t}) \right| \leq 2(1-(1-\epsilon)^t) \leq 2\epsilon t$$</p>
<p>두 확률분포의 차이의 절댓값($\bf \left| p_{mistake}(s_{t})-p_{train}(s_{t}) \right|$)의 최댓값은 2이고 $\bf -(1-\epsilon)^t \leq -(1-\epsilon t)$ for $\epsilon \in \left[0,1\right]$이므로 $\bf \left| p_{mistake}(s_{t})-p_{train}(s_{t}) \right|$의 upper bound는 $2\epsilon t$이 된다.</p>
<p>cost의 기댓값은 아래와 같이 전개된다.</p>
<p>$$\bf \underset{t}{\sum} \mathbb{E_{p_{\theta}(s_{t})}} \left[ c_{t} \right] = \underset{t}{\sum}\underset{s_{t}}{\sum} p_{\theta}(s_{t})c_{t}(s_{t})$$</p>
<p>$$\bf p_\theta c = p_{train}c + (p_\theta - p_{train})c \ \ \ \because \bf p_\theta = p_{train} + p_\theta - p_{train}$$ </p>
<p>$$\bf \leq p_{train}c + |p_\theta-p_{train}|c \leq p_{train}c + |p_\theta-p_{train}|c_{max}$$</p>
<p>$$\bf p_\theta = p_{train} + p_\theta - p_{train}$$</p>
<p>$$\bf \underset{t}{\sum} \mathbb{E_{p_{\theta}(s_{t})}} \left[ c_{t} \right] = \underset{t}{\sum}\underset{s_{t}}{\sum} p_{\theta}(s_{t})c_{t}(s_{t}) \leq \underset{t}{\sum}\underset{s_{t}}{\sum} p_{train}(s_{t})c_{t}(s_{t}) + \left| p_{\theta}(s_{t}) -p_{train}(s_{t})\right|c_{max}$$</p>
<p>여기서 $\bf c_{max}$(worst possible cost)는 cost definition에 의해 1이고 $p_{train}$의 cost 기댓값 $\bf \underset{s_{t}}{\sum}p_{train} (s_{t})c_{t}(s_{t})$은 $\epsilon$이기때문에 아래와 같이 전개된다.</p>
<p>$$\bf \underset{t}{\sum} \mathbb{E_{p_{\theta}(s_{t})}} \left[ c_{t} \right] \leq \underset{t}{\sum}\epsilon + 2 \epsilon t \leq \epsilon T + 2 \epsilon T^{2}$$</p>
<p>결국 $\bf O(\epsilon T^{2})$이 된다.</p>

    </div>
      


    
    
    

    <footer class="post-footer">
          
        
        <div class="post-tags">
            <a href="/tags/Deep-Learning/" rel="tag"><i class="fa fa-tag"></i> Deep Learning</a>
          
        </div>
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
              <a href="/2019/08/31/2019-08-31-PRML-1/" rel="next" title="PRML 1 Introduction">
                <i class="fa fa-chevron-left"></i> PRML 1 Introduction
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
              <a href="/2020/03/08/2020-02-25-DQN/" rel="prev" title="Double DQN  ">
                Double DQN   <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
    </footer>
  </div>
  
  
  
  </article>

  </div>


          </div>
          
    
    
  <div class="comments" id="comments">
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
    </div>
  </div>
  
  


        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            목차
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            흝어보기
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">

          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Juhwak Kim</p>
  <div class="site-description motion-element" itemprop="description"></div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">29</span>
          <span class="site-state-item-name">포스트</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">카테고리</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">태그</span>
        </a>
      </div>
    
  </nav>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="https://github.com/juhwakKim" title="GitHub &rarr; https://github.com/juhwakKim" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i></a>
      </span>
    
      <span class="links-of-author-item">
      
      
      
        
      
        <a href="mailto:juhk1017@naver.com" title="E-Mail &rarr; mailto:juhk1017@naver.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i></a>
      </span>
    
  </div>



        </div>
      </div>
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Terminology-amp-notation"><span class="nav-number">1.</span> <span class="nav-text">Terminology &amp; notation</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#observation-과-state의-차이"><span class="nav-number">1.0.1.</span> <span class="nav-text">observation 과 state의 차이</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Imitation-Learning"><span class="nav-number">2.</span> <span class="nav-text">Imitation Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#문제-개선"><span class="nav-number">2.0.1.</span> <span class="nav-text">문제 개선</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DAgger"><span class="nav-number">2.1.</span> <span class="nav-text">DAgger</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#실패-원인"><span class="nav-number">2.2.</span> <span class="nav-text">실패 원인</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Non-Markovian-behavior"><span class="nav-number">2.2.1.</span> <span class="nav-text">Non-Markovian behavior</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Multimodal-behavior"><span class="nav-number">2.2.2.</span> <span class="nav-text">Multimodal behavior</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Output-mixture-of-Gaussians"><span class="nav-number">2.2.3.</span> <span class="nav-text">Output mixture of Gaussians</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#latent-variable-models"><span class="nav-number">2.2.4.</span> <span class="nav-text">latent variable models</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#autoregressive-discretization"><span class="nav-number">2.2.5.</span> <span class="nav-text">autoregressive discretization</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Imitation-learning-recap"><span class="nav-number">2.3.</span> <span class="nav-text">Imitation learning: recap</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Imitation-learning의-한계"><span class="nav-number">2.3.1.</span> <span class="nav-text">Imitation learning의 한계</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#learning-without-imitation"><span class="nav-number">2.3.2.</span> <span class="nav-text">learning without imitation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#cost-function-for-imitation-learning"><span class="nav-number">2.3.3.</span> <span class="nav-text">cost function for imitation learning</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Distribution-mismatch-analysis"><span class="nav-number">2.3.4.</span> <span class="nav-text">Distribution mismatch analysis</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          
        </div>
      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Juhwak Kim</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.9.0</div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.3.0</div>

        








        
      </div>
    </footer>

    

  </div>

  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

<script src="/js/utils.js?v=7.3.0"></script>
  <script src="/js/motion.js?v=7.3.0"></script>


  <script src="/js/schemes/muse.js?v=7.3.0"></script>


<script src="/js/next-boot.js?v=7.3.0"></script>






  















  <script src="/js/local-search.js?v=7.3.0"></script>














  

  
    
      <script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', function() {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    
  

  

  


  
  <script src="/js/scrollspy.js?v=7.3.0"></script>
<script src="/js/post-details.js?v=7.3.0"></script>


    
<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://juhk1017.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>
<script>
  var disqus_config = function() {
    this.page.url = "https://juhwakkim.github.io/2020/02/25/2020-02-25-cs285-1/";
    this.page.identifier = "2020/02/25/2020-02-25-cs285-1/";
    this.page.title = 'CS285 Fa19 Deep Reinforcement Learning, Decision Making, and Control';};
  function loadComments() {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: disqus_config
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://juhk1017.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  }
    window.addEventListener('load', loadComments, false);
  
</script>

</body>
</html>
